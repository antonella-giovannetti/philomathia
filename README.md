# README des exercices Jupyter Notebook - "Philomathia"

## Introduction
Ce document fournit un aperçu des exercices effectués dans le cadre du projet "Philomathia". Les exercices aborde certaines notions mathématiques et de la programmation en Python, utilisant des bibliothèques comme NumPy, Pandas, Matplotlib et d'autres, nécessaire pour le Machine Learning. 

## Table des Matières
- Algèbre linéaire
- Probabilités et Statistique
- Calcul de dérivée

## Exercices;

### Algèbre Linéaire
- **Job 0:** Manipulation de vecteurs avec NumPy.
- **Job 1:** Addition de vecteurs.
- **Job 2:** Opérations sur des matrices, vérification de la possibilité d'addition et de multiplication matricielle.
- **Job 3 à 5:** Diverses opérations sur les matrices, incluant la transposition, la multiplication et la manipulation spécifique des matrices.
- **Job 6:** Utilisation de la matrice identité dans la multiplication matricielle.
- **Job 7 à 9:** Exploration de l'inverse d'un nombre et d'une matrice, et calcul des matrices inversibles.

### Probabilités et Statistique
- **Job 10 à 14:** Expériences avec des lancers de pièces et de dés, analyse de données générées aléatoirement.
- **Job 15:** Analyse statistique de données de vins, utilisation de Pandas pour la visualisation des données.
- **Job 16:** Simulation de la Loi Normale.

### Calcul de Dérivée
- **Job 17:** Calcul de dérivées de différentes fonctions mathématiques à l'aide de la librairie SymPy.

## Conclusion
Ce document sert de guide pour comprendre la structure et le contenu des exercices réalisés, qui forment une bonne base pour le Machine Learning. Les concepts d'algèbre linéaire, de probabilités, de statistiques et de calcul différentiel sont essentiels pour comprendre les algorithmes de Machine Learning. Par exemple, les opérations matricielles sont cruciales pour les réseaux de neurones, les probabilités et les statistiques sont fondamentales pour l'évaluation des modèles, et le calcul différentiel est au cœur des méthodes d'optimisation comme la descente de gradient.